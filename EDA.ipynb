{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import plotly.graph_objects as go \n",
    "import plotly.express as px #for colors\n",
    "\n",
    "#prices\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from entsoe import EntsoePandasClient\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Fluvius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explain how Fluvius data has been used, correlation, clustering?,graphs, etc\n",
    "consumption = pd.read_csv('data/consumption.csv')\n",
    "#in kWh by default see legend doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stat_time consumption\n",
    "consumption = consumption.drop(columns=['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption #do only for one profile, temporary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here could add boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for id == 173 make a numpy array with consumption column\n",
    "cons_1 = consumption[consumption['id'] == 272] #low\n",
    "cons_1 = cons_1.groupby(['date']).sum()\n",
    "# cons_1 = cons_1['consumption'].to_numpy()\n",
    "cons_2 = consumption[consumption['id'] == 173] #median\n",
    "cons_2 = cons_2.groupby(['date']).sum()\n",
    "# cons_2 = cons_2['consumption'].to_numpy()\n",
    "cons_3 = consumption[consumption['id'] == 550] #high\n",
    "cons_3 = cons_3.groupby(['date']).sum()\n",
    "# cons_3 = cons_3['consumption'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_green = '#228A83'\n",
    "dark_green = '#2E5651'\n",
    "blue = '#002060'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the df_grouped with colors light_green and blue (earlier defined) using plotly\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=cons_1.index, y=cons_1['consumption'], mode='lines', name='Low', line=dict(color=dark_green)))\n",
    "fig.add_trace(go.Scatter(x=cons_1.index, y=cons_2['consumption'], mode='lines', name='median', line=dict(color=blue)))\n",
    "# fig.add_trace(go.Scatter(x=cons_1.index, y=cons_3['consumption'], mode='lines', name='high', line=dict(color=light_green)))\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Consumption profiles Fluvius\",\n",
    "        'font': {\n",
    "            'color': '#2E5651'\n",
    "        }\n",
    "    },\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='kWh per day'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in cons_1 print the sum of consumption and the stad dev\n",
    "print('Low consumption profile')\n",
    "print('Sum of consumption:', cons_1['consumption'].sum()) \n",
    "print('Standard deviation:', cons_1['consumption'].std())\n",
    "print('Medium consumption profile')\n",
    "print('Sum of consumption:', cons_2['consumption'].sum())\n",
    "print('Standard deviation:', cons_2['consumption'].std())\n",
    "print('High consumption profile')\n",
    "print('Sum of consumption:', cons_3['consumption'].sum())\n",
    "print('Standard deviation:', cons_3['consumption'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cons_3) #quarterly data, all same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cons_1\n",
    "print('Average:', cons_1['consumption'].mean())\n",
    "print('Max:', cons_1['consumption'].max())\n",
    "print('Min:', cons_1['consumption'].min())\n",
    "print('Standard deviation:', cons_1['consumption'].std())\n",
    "print('Count:', cons_1['consumption'].count())\n",
    "#cons_2\n",
    "print('Average:', cons_2['consumption'].mean())\n",
    "print('Max:', cons_2['consumption'].max())\n",
    "print('Min:', cons_2['consumption'].min())\n",
    "print('Standard deviation:', cons_2['consumption'].std())\n",
    "print('Count:', cons_2['consumption'].count())\n",
    "#cons_3\n",
    "print('Average:', cons_3['consumption'].mean())\n",
    "print('Max:', cons_3['consumption'].max())\n",
    "print('Min:', cons_3['consumption'].min())\n",
    "print('Standard deviation:', cons_3['consumption'].std())\n",
    "print('Count:', cons_3['consumption'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_loss = 0.3 #tocheck... impact as ell on profile, probably a bit lower\n",
    "#explain where weather data has been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weather data\n",
    "weather = pd.read_csv('data/weather.csv')\n",
    "\n",
    "#make columns now for each profile, create first column and then for loop 1 to 4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove start_time\n",
    "weather = weather.drop(columns=['start_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupe weather by date and take the mean\n",
    "weather_sum = weather.groupby(['date']).sum()\n",
    "weather_mean = weather.groupby(['date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Adding Solar Irradiation Trace\n",
    "fig.add_trace(go.Scatter(x=weather_sum.index, y=weather_sum['solar_irradiation'], mode='lines', name='Solar irradiation', line=dict(color=light_green)))\n",
    "\n",
    "# Adding Temperature Trace, setting it to the secondary y-axis\n",
    "fig.add_trace(go.Scatter(x=weather_sum.index, y=weather_mean['temperature'], mode='lines', name='Temperature', line=dict(color='gray'), yaxis='y2'))\n",
    "\n",
    "# Updating layout to include a secondary y-axis\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title='Date'),\n",
    "    yaxis=dict(title='Solar Irradiation (W/m²)'),\n",
    "    yaxis2=dict(title='Temperature (°C)', overlaying='y', side='right'),\n",
    "    title={\n",
    "        'text': \"Weather data needed for PV production predictions\",\n",
    "        'font': {\n",
    "            'color': '#2E5651'\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prod(df, efficiency_loss): #no need area panel\n",
    "    #use temp and irradiance to calculate the production in df\n",
    "    df['prod_one_kw_panel'] = (1 - 0.005 * (df['temperature'] - 25)) * df['solar_irradiation'] * efficiency_loss #make it profile name!!\n",
    "    print('Done')\n",
    "    return df\n",
    "\n",
    "weather_with_prod = calc_prod(weather, efficiency_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sum of prod_one_kw_panel\n",
    "print('Total production of 1 kW panel:', weather_with_prod['prod_one_kw_panel'].sum()/1000, 'kWh')\n",
    "print('Total irrandiance in BE:', weather_with_prod['solar_irradiation'].sum()/1000, 'kWh/m²/year') #W/m² is here one hour timestep, is an instant (average here) delivery of power, not energy\n",
    "#The yearly solar irradiance in Belgium typically varies around 1,000 to 1,150 kWh per square meter (kWh/m²/year)\n",
    "\n",
    "#Average consumption in Belgium is 4-5 persons 7,500 kWh/year (profile 2?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_panel_1 = 1\n",
    "area_panel_2 = 5\n",
    "area_panel_3 = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column prod_1, prod_2, prod_3 in weather_with_prod by multiplying prod_one_kw_panel with area_panel_1, area_panel_2, area_panel_3\n",
    "weather_with_prod['prod_1'] = weather_with_prod['prod_one_kw_panel'] * area_panel_1\n",
    "weather_with_prod['prod_2'] = weather_with_prod['prod_one_kw_panel'] * area_panel_2\n",
    "weather_with_prod['prod_3'] = weather_with_prod['prod_one_kw_panel'] * area_panel_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_with_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sum prod_1\n",
    "print('Total production of 1 kW panel:', weather_with_prod['prod_1'].sum()/1000, 'kWh')\n",
    "print('Total production of 5 kW panel:', weather_with_prod['prod_2'].sum()/1000, 'kWh')\n",
    "print('Total production of 15 kW panel:', weather_with_prod['prod_3'].sum()/1000, 'kWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete start_time from weather_with_prod\n",
    "# weather_with_prod = weather_with_prod.drop(columns=['start_time', 'solar_irradiation', 'temperature'])\n",
    "weather_with_prod = weather_with_prod.drop(columns=['solar_irradiation', 'temperature'])\n",
    "\n",
    "#group weather_with_prod by date and take the sum\n",
    "weather_with_prod = weather_with_prod.groupby(['date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_with_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot prod_1, prod_2, prod_3\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=weather_with_prod.index, y=weather_with_prod['prod_1'], mode='lines', name='1 kW panel', line=dict(color=dark_green)))\n",
    "fig.add_trace(go.Scatter(x=weather_with_prod.index, y=weather_with_prod['prod_2'], mode='lines', name='5 kW panel', line=dict(color=blue)))\n",
    "fig.add_trace(go.Scatter(x=weather_with_prod.index, y=weather_with_prod['prod_3'], mode='lines', name='15 kW panel', line=dict(color=light_green)))\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Consumption profiles Fluvius\",\n",
    "        'font': {\n",
    "            'color': '#2E5651'\n",
    "        }\n",
    "    },\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='kWh'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_array_from_df(df, col_name):\n",
    "    return df[col_name].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take array from it and do 4 replication same length normally, divide uniformly and by 1000 (to get KWh per quarter)\n",
    "#same as make_Wp_to_kWh function\n",
    "prod_1 = make_array_from_df(weather_with_prod, 'prod_1')/1000\n",
    "prod_2 = make_array_from_df(weather_with_prod, 'prod_2')/1000\n",
    "prod_3 = make_array_from_df(weather_with_prod, 'prod_3')/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print total consumption per cons\n",
    "print(f'sum cons 1: {cons_1.sum()}, sum cons 2: {cons_2.sum()}, sum cons 3: {cons_3.sum()} kWh/year')\n",
    "print(f'sum prod 1: {prod_1.sum()}, sum prod 2: {prod_2.sum()}, sum prod 3: {prod_3.sum()} kWh/year')\n",
    "#changed panel_1 and efficiency loss!!! maybe need to be increased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from file\n",
    "prices_fluvius = np.loadtxt('data/prices_fluvius.csv', delimiter=',')\n",
    "prices_fluvius #length is 8760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def rolling_average_by_chunks(data, chunk_size):\n",
    "  \"\"\"Averages data by chunk_size, returning an array of the same length.\n",
    "\n",
    "  Args:\n",
    "    data: A NumPy array of any dimension.\n",
    "    chunk_size: The size of the rolling window for averaging.\n",
    "\n",
    "  Returns:\n",
    "    A NumPy array with the same dimensions as data, containing the rolling\n",
    "    averages.\n",
    "  \"\"\"\n",
    "  if chunk_size <= 1:\n",
    "    raise ValueError(f\"chunk_size must be greater than 1, got {chunk_size}\")\n",
    "\n",
    "  if len(data) % chunk_size != 0:\n",
    "    raise ValueError(\n",
    "        f\"data length {len(data)} must be a multiple of chunk_size {chunk_size}\"\n",
    "    )\n",
    "\n",
    "  # We can use np.lib.stride_tricks.sliding_window_view to create a 2D view of the\n",
    "  # data that allows us to calculate the averages across chunks. However, this\n",
    "  # method has a known issue where it doesn't support complex data types. As a\n",
    "  # workaround, we can reshape the data to 2D if it has more than one dimension\n",
    "  # and then reshape it back to its original shape after the calculation.\n",
    "  if data.ndim > 1:\n",
    "    data_reshaped = data.reshape(-1, data.shape[-1])\n",
    "  else:\n",
    "    data_reshaped = data\n",
    "\n",
    "  # Create a 2D view of the data with overlapping windows of size chunk_size.\n",
    "  data_strided = np.lib.stride_tricks.sliding_window_view(data_reshaped, window_shape=(chunk_size,))\n",
    "\n",
    "  # Calculate the mean along the last dimension (axis=0) to get the rolling averages.\n",
    "  averages = np.mean(data_strided, axis=0)\n",
    "\n",
    "  if data.ndim > 1:\n",
    "    averages = averages.reshape(data.shape)\n",
    "\n",
    "  return averages\n",
    "\n",
    "# Example usage:\n",
    "# data = np.arange(72)\n",
    "# chunk_size = 24\n",
    "# output = rolling_average_by_chunks(data, chunk_size)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_fluvius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_1= [122.62,\n",
    "    122.62, 119.30, 109.02, 88.72, 83.85, 109.53, 125.38, 173.68,\n",
    "    188.11, 194.25, 178.99, 165.76, 145.10, 125.00, 134.32, 140.00,\n",
    "    141.91, 167.62, 197.74, 183.60, 202.10, 140.35, 163.23, 127.11, 127.11\n",
    "]\n",
    "may_1 = [109.9,\n",
    "    109.90, 99.90, 95.49, 90.88, 87.61, 88.00, 87.44, 91.89,\n",
    "    90.49, 88.50, 81.29, 67.50, 54.45, 34.69, 30.00, 41.12,\n",
    "    51.80, 49.33, 89.42, 109.55, 123.35, 121.72, 117.90, 111.04, 111.04 \n",
    "]\n",
    "\n",
    "aug_1 = [68.47,\n",
    "    68.47, 58.89, 57.86, 56.94, 57.90, 63.40, 75.34, 90.91,\n",
    "    90.58, 88.18, 77.00, 67.07, 67.10, 61.96, 53.09, 48.26,\n",
    "    54.60, 67.94, 79.59, 95.05, 106.41, 112.42, 102.55, 92.78, 92.78\n",
    "]\n",
    "\n",
    "nov_1 = [65.31,\n",
    "    65.31, 64.20, 50.23, 26.48, 23.75, 30.13, 47.99, 68.07,\n",
    "    66.88, 69.23, 46.22, 43.50, 47.64, 38.92, 32.84, 37.28,\n",
    "    51.58, 63.40, 80.46, 71.80, 57.48, 40.15, 40.77, 23.00, 23.00\n",
    "]\n",
    "#create list from 0 to 23\n",
    "time_intervals = list(range(24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "light_green = '#228A83'\n",
    "dark_green = '#2E5651'\n",
    "blue = '#002060'\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=feb_1, mode='lines', name='February', line=dict(color=light_green, shape='vh')))\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=may_1, mode='lines', name='May', line=dict(color=blue, shape='vh')))\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=aug_1, mode='lines', name='August', line=dict(color=dark_green, shape='vh')))\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=nov_1, mode='lines', name='November', line=dict(color='gray', shape='vh')))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Day-ahead_prices Belgium in 2023\",\n",
    "        'font': {\n",
    "            'color': '#2E5651'\n",
    "        }\n",
    "    },\n",
    "    xaxis_title='Time intervals (hours)',\n",
    "    yaxis_title='Price (€/MWh)'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot feb_1, may_1, aug_1, nov_1 with time intervals\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=feb_1, mode='lines', name='February', line=dict(color=dark_green)))\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=may_1, mode='lines', name='May', line=dict(color=blue)))\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=aug_1, mode='lines', name='August', line=dict(color=light_green)))\n",
    "fig.add_trace(go.Scatter(x=time_intervals, y=nov_1, mode='lines', name='November', line=dict(color='gray')))\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Prices Fluvius\",\n",
    "        'font': {\n",
    "            'color': '#2E5651'\n",
    "        }\n",
    "    },\n",
    "    xaxis_title='Time intervals (hours)',\n",
    "    yaxis_title='€/MWh'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 robbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/robbe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df #output from other file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er ontbreekt data maar blc - moet wel zorgen zelfde lengte voor analyysis later...\n",
    "\n",
    "Also mistmatch on s'en branle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide consumption and production data by 1000 to Kwh\n",
    "df['consumption'] = df['consumption']/1000\n",
    "df['production'] = df['production']/1000\n",
    "#multiply consumption and production data by 1/12\n",
    "df['consumption'] = df['consumption']*1/12\n",
    "df['production'] = df['production']*1/12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sum of consumption and production\n",
    "print('sum of consumption:', df['consumption'].sum())\n",
    "print('sum of production:', df['production'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make time column datetime\n",
    "df['time'] = pd.to_datetime(df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make in df a new hour column, day of the week and month\n",
    "df['hour'] = pd.to_datetime(df['time']).dt.hour\n",
    "df['day'] = pd.to_datetime(df['time']).dt.day_name()\n",
    "df['month'] = pd.to_datetime(df['time']).dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['time'].dt.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make first adjustments for dates missing, done in csv... so load these on Github (no excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31 March, Mai, minuit rajouté et que 10 Février jusqu'au 30 Juin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuals from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for each column consumption and column production print average, max and min\n",
    "# print('Consumption')\n",
    "# print('Average:', df['consumption'].mean())\n",
    "# print('Max:', df['consumption'].max())\n",
    "# print('Min:', df['consumption'].min())\n",
    "# print('Standard deviation:', df['consumption'].std())\n",
    "# print('Count:', df['consumption'].count())\n",
    "# print('Production')\n",
    "# print('Average:', df['production'].mean())\n",
    "# print('Max:', df['production'].max())\n",
    "# print('Min:', df['production'].min())\n",
    "# print('Standard deviation:', df['production'].std())\n",
    "# print('Count:', df['production'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count is not exact but blc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the number of unique values in df['date']\n",
    "print('Number of unique values in date:', df['date'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df_merged from df removing hour, time\n",
    "df_merged = df.drop(['hour', 'time', 'day', 'month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df_grouped which is the averaged grouped by date\n",
    "df_grouped = df_merged.groupby(['date']).sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation (one cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of kW (kilowatts) rather than kWh (kilowatt-hours) is suggested because the data points seem to represent the instantaneous power production or consumption at each timestamp, not the cumulative energy used or produced over time, which would be measured in kWh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the df_grouped with colors light_green and blue (earlier defined) using plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_grouped.index, y=df_grouped['consumption'], mode='lines', name='Consumption', line=dict(color=light_green)))\n",
    "fig.add_trace(go.Scatter(x=df_grouped.index, y=df_grouped['production'], mode='lines', name='Production', line=dict(color=blue)))\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Daily consumption and production Robbe\",\n",
    "        'font': {\n",
    "            'color': '#2E5651'\n",
    "        }\n",
    "    },\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='kWh per day'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each column consumption and column production print average, max and min\n",
    "#sum\n",
    "print('sum of consumption:', df_grouped['consumption'].sum())\n",
    "print('sum of production:', df_grouped['production'].sum())\n",
    "print('Consumption')\n",
    "print('Average:', df_grouped['consumption'].mean())\n",
    "print('Max:', df_grouped['consumption'].max())\n",
    "print('Min:', df_grouped['consumption'].min())\n",
    "print('Standard deviation:', df_grouped['consumption'].std())\n",
    "#print volatility\n",
    "print('Volatility:', df_grouped['consumption'].std()/df_grouped['consumption'].mean()*100)\n",
    "print('Count:', df_grouped['consumption'].count())\n",
    "print('Production')\n",
    "print('Average:', df_grouped['production'].mean())\n",
    "print('Max:', df_grouped['production'].max())\n",
    "print('Min:', df_grouped['production'].min())\n",
    "print('Standard deviation:', df_grouped['production'].std())\n",
    "#print volatility\n",
    "print('Volatility:', df_grouped['production'].std()/df_grouped['production'].mean()*100)\n",
    "print('Count:', df_grouped['production'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then visualisation of production and consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to run and blc last cell already preprocess, no need visualize prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DayAheadPrices:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = EntsoePandasClient(api_key=api_key)\n",
    "\n",
    "    def fetch_and_print_day_ahead_prices(self, start_date, end_date, country_code='BE'):\n",
    "        \"\"\"Fetches and prints the day ahead prices for a specified country within a date range.\"\"\"\n",
    "        # Convert start_date and end_date to pandas Timestamp with timezone\n",
    "        timezone = 'Europe/Brussels'\n",
    "        date_start = pd.Timestamp(start_date, tz=timezone)\n",
    "        date_end = pd.Timestamp(end_date, tz=timezone)\n",
    "\n",
    "        # logging.info(f'Fetching day ahead prices from ENTSO-E for {country_code}: {date_start} to {date_end}')\n",
    "        \n",
    "        # Fetch day ahead prices\n",
    "        try:\n",
    "            day_ahead_prices_df = self.client.query_day_ahead_prices(country_code=country_code, start=date_start, end=date_end)\n",
    "            # Convert the DataFrame to a dictionary with the date as the key and a list of prices as the value\n",
    "            prices_by_day = {}\n",
    "            for date, group in day_ahead_prices_df.groupby(day_ahead_prices_df.index.date):\n",
    "                prices_by_day[str(date)] = group.values.tolist()\n",
    "                \n",
    "            print(\"Day Ahead Prices (€/MWh):\")\n",
    "            print(prices_by_day)\n",
    "            return prices_by_day\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while fetching data: {e}\")\n",
    "\n",
    "\n",
    "api_key = 'eaccd9d9-2a8e-42b0-9257-2aa47096934e' # Replace with your actual API key\n",
    "start_date = '2023-02-10'\n",
    "end_date = '2023-06-30'\n",
    "#create DayAheadPrices elem\n",
    "elem = DayAheadPrices(api_key)\n",
    "robbe_prices = DayAheadPrices.fetch_and_print_day_ahead_prices(elem,start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 31-03-2023 and 31-05-2023 from robbe_prices\n",
    "robbe_prices.pop('2023-03-31', None)\n",
    "robbe_prices.pop('2023-05-31', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robbe_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(robbe_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_long_array(prices_dict):\n",
    "    # Concatenate the lists of prices into a single numpy array\n",
    "    all_prices = np.concatenate([np.array(prices_dict[date]) for date in prices_dict])\n",
    "    return all_prices\n",
    "\n",
    "# Applying the function to 'robbe_prices' to create the numpy array\n",
    "robbe_prices_array = create_long_array(robbe_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(robbe_prices_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robbe_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_prices_within_date_range(prices, start_date, end_date):\n",
    "    # Convert string dates to datetime objects for comparison\n",
    "    start_date_dt = datetime.strptime(start_date, '%Y/%m/%d')\n",
    "    end_date_dt = datetime.strptime(end_date, '%Y/%m/%d')\n",
    "\n",
    "    # Create a new dictionary to store the filtered prices within the date range\n",
    "    filtered_prices_within_date_range = {\n",
    "        date: price for date, price in prices.items()\n",
    "        if start_date_dt <= datetime.strptime(date, '%Y-%m-%d') <= end_date_dt\n",
    "    }\n",
    "\n",
    "    return filtered_prices_within_date_range\n",
    "\n",
    "# filtered_robbe_prices = filter_prices_within_date_range(robbe_prices, '2023/02/09', '2023/06/30')\n",
    "\n",
    "\n",
    "# prices_values = list(prices.values())\n",
    "# prices_values = prices_values[:-1]\n",
    "# prices_values_one_list = [sublist[:24] + [0] * (24 - len(sublist)) if len(sublist) > 24 else sublist + [0] * (24 - len(sublist)) for sublist in prices_values]\n",
    "# prices_values_one_list = [item for sublist in prices_values_one_list for item in sublist]\n",
    "\n",
    "# #make numpy\n",
    "# prices_values_one_list = np.array(prices_values_one_list)\n",
    "# #dvide by 1000 to get Eur/kWh\n",
    "# prices_values_one_list = prices_values_one_list/1000\n",
    "\n",
    "# def length_distribution(list_of_lists):\n",
    "#     length_count = {}\n",
    "#     for i, sublist in enumerate(list_of_lists, start=1):\n",
    "#         length = len(sublist)\n",
    "#         if length in length_count:\n",
    "#             length_count[length].append(i)\n",
    "#         else:\n",
    "#             length_count[length] = [i]\n",
    "    \n",
    "#     # Print the length distribution\n",
    "#     print(\"Length Distribution:\")\n",
    "#     for length, indices in sorted(length_count.items()):\n",
    "#         print(f\"Length {length}: {len(indices)} sublists at indices {indices}\")\n",
    "\n",
    "# length_distribution(prices_values) #remove last elem and put zero or remove last.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
